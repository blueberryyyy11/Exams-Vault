Когда мы говорим «память» и не указываем, какую именно память, что мы имеем в виду? Основную память или оперативную память. Когда мы говорим о, скажем, жёстком диске или каких-то сменных носителях, то будем называть их точным именем, допустим, жёсткий диск или дополнительное хранилище. 

В принципе, компьютеры могут работать без жёсткого диска, без каких-то постоянных носителей. Многие компьютеры именно так и работают, в частности компьютеры небольших устройств. 
![[Drawing 2025-01-21 13.06.34.excalidraw]]

Память входит в эту основную структуру. Под компьютером мы подразумеваем комбинацию памяти, процессора или каких-то модулей для ввода-вывода информации. Все эти части соединены между собой системной шиной, которая используется для высокоскоростной передачи информации между этими частями. Память не непостоянная. Данные теряются при отключении питания. Каждый раз, когда компьютер включается заново, память полностью чистая, с самого начала заполняется, используется как операционной системой, так и программами.

Память можно рассматривать просто как набор ячеек с адресами. В каждой ячейке может храниться какая-то информация или какая-то инструкция, что, по сути, тоже информация. 

Память — это такой же ресурс компьютера. Конечно, все процессы хотят её использовать. Процессы были бы счастливы, если бы они могли использовать всю память или если бы память была бесконечна. Но это не так. И, несмотря на то, что память относительно дешёвая и за последние десятки лет почти постоянно дешевеет, приложения также продолжают быть всё более и более прожорливыми. Сегодня даже веб-сайты иногда имеют, если не публично, то неформально, какие-то системные требования. И очень часто всё, что связано с интернетом, браузерами, очень прожорливо в плане памяти. 
Несмотря на то что память — это оперативная память, когда мы касаемся управления памятью, то мы будем затрагивать такую тему, как работа со вторичным носителем, в частности жёстким диском. Память, как и всё остальное в компьютере, намного медленнее, чем центральный процессор. Этот факт, как обычно, очень сильно влияет на то, как мы будем управлять этим ресурсом.

Итак, перед операционной системой стоит несколько основных задач, когда дело касается управления памятью:

1. Распределение.
2. Защита.
3. Разделение.
4. Логическая и физическая организация.

Давайте поговорим о каждом из них. В частности, под распределением понимается распределение этого ресурса — памяти — между разными процессами, программами, которые хотят использовать эту память. Это звучит логично, но тут нужно помнить, что, когда программист пишет программу, он не должен знать и не знает, где в памяти эта программа будет находиться. Он не знает, какого размера память на этом компьютере доступна. Не знает, в какой-то момент времени сколько памяти будет доступно этой программе. Он не знает, где в памяти физически будет его программа находиться. Для программиста, который пишет эту программу, и для самой программы не должно быть разницы, находится ли в данный момент программа где-нибудь в начале адресного пространства или в конце. Может быть, в какой-то момент эта программа была из памяти перенесена на жёсткий диск, а потом перенесена обратно. 

И последний пункт, он, возможно, сейчас не очень понятен: обращения к памяти должны конвертироваться в настоящий физический адрес. Мы увидим чуть позже в этой лекции, что я имею в виду. 

Защита — это тоже очень очевидное требование. Если процесс использует какую-то память, он туда что-то записывает, он оттуда что-то читает. Он как-то считает эту память своей. Естественно, другой процесс не должен иметь возможность прийти и как-то там всё перетереть или использовать по-своему.
При этом, одновременно с этим, иногда процессы должны иметь возможность использовать общую память, если они работают над какой-то общей задачей. Это требование называется *разделением*. Доступ к одному участку памяти должен быть потенциально доступен нескольким процессам. Это иногда не просто требование процессов, это также зачастую просто наиболее эффективный способ использования памяти. Если данные, используемые разными процессами, являются одними и теми же, то эффективнее всего давать им доступ к этим данным, чем делать копию для каждого процесса.

Опять же, чуть позже увидим, как эти идеи реализуются в современных операционных системах. Требование, которое называется логической организацией, — это организация памяти с точки зрения процесса, с точки зрения программы. Это не обязательно совпадает с организацией, которая физически на самом деле происходит в компьютере. И это не проблема. На самом деле это решение проблемы. Память обычно растёт линейно, и к ней можно относиться как к такой полке с книгами, которая заполняется слева направо: вы кладёте книги слева и добавляете каждую книгу в левую часть. Программы могут состоять из разных модулей, которые создавались, компилировались и запускались отдельно друг от друга. Они используют разные области памяти, имеют разные уровни доступа. Кто-то может только читать эту память, кто-то может читать и записывать.

На операционную систему ложится очень много ответственности. Операционная система должна учитывать все эти сложности, учитывать все эти требования, и в конечном итоге для программ и процессов всё, что связано с памятью, должно быть очень удобно и просто, хотя на самом деле всё очень сложно и запутано.

### Физическая организация памяти

Физическая организация — это то, что происходит на самом устройстве. Программы, как правило, не должны касаться физической организации памяти, если только это не программист, который создаёт операционную систему.

Центральная тема этой лекции — организация памяти. Как, имея ограниченные ресурсы и множество процессов, организовать использование памяти? Естественно, мы не можем просто дать доступ ко всей памяти всем процессам одновременно и надеяться, что они не будут вмешиваться друг в друга. Всё намного сложнее.

### Первые подходы к управлению памятью

Первая идея, которая пришла людям в голову — это использование единого постоянного выделения памяти (Continuous Allocation). Самый простой вариант. Старые операционные системы, такие как MS-DOS могли запускать только один процесс, и в этом процессе могла быть только одна задача. Там не было многозадачности. Это означало, что в любой момент времени запущен только один процесс (не считая самой операционной системы).

В такой системе вся память отдавалась одному процессу. Когда процесс завершался, память освобождалась и могла быть передана следующему процессу. Это удобно, так как не нужно было думать о делении памяти на области или о защите памяти от других процессов. Однако такая система не поддерживала многозадачность.

### Переход к многозадачности

Когда появилась необходимость в многозадачности, стало ясно, что просто отдавать всю память одному процессу невозможно. Нужно было научиться делить память на участки. Один из первых подходов — деление памяти на одинаковые блоки фиксированного размера. Например, вся память делится на блоки по 8 МБ. Если процессу нужна память, ему выделяется один из таких блоков.

Этот подход был прост в реализации, но имел существенные недостатки:
![[Drawing 2025-01-21 13.30.49.excalidraw]]
- **Неэффективность использования памяти**: если процессу требуется меньше памяти, остаётся неиспользуемое пространство (внутренняя фрагментация).
    
- **Ограниченность гибкости**: если процессу требуется больше памяти, чем размер одного блока, ему будет сложно разместиться.
    

Для решения этих проблем предложили использовать блоки разного размера (2 МБ, 4 МБ, 8 МБ и т. д.). 
Это немного снизило фрагментацию, так как теперь процессу можно было выделить блок подходящего размера. Однако добавилась сложность управления: система должна была отслеживать, какие блоки доступны, и подбирать наиболее подходящий для процесса.

### Динамическое выделение памяти

Следующим шагом стало динамическое выделение памяти. Теперь блоки памяти создавались по запросу процесса и точно соответствовали его потребностям. Это решило проблему внутренней фрагментации. Однако появилось новое препятствие — внешняя фрагментация. Память со временем превращалась в «решето»: свободные участки были разбросаны по всей памяти.
Для борьбы с внешней фрагментацией использовали метод уплотнения (compaction): занятые блоки памяти сдвигались, чтобы освободить непрерывный участок свободного пространства. Однако это требовало дополнительных затрат времени и ресурсов.

### Алгоритмы выбора свободных блоков

При динамическом выделении памяти возникла проблема выбора подходящего свободного блока. Основные алгоритмы:

1. **Best Fit**: выбор самого маленького блока, который подходит процессу. Этот алгоритм минимизирует потери памяти, но требует больше времени для поиска.
    
2. **First Fit**: выбор первого подходящего блока. Быстрее, но может привести к большему числу мелких фрагментов.
    
3. **Next Fit**: продолжение поиска с места последнего выделения. Уменьшает количество обращений к памяти.

### Виртуальная память

Поговорим о той идее, которая впоследствии стала использоваться в современной концепции **виртуальной памяти** — это подкачка страниц. Давайте разделим память на какие-то блоки. Но это просто логические блоки, это не значит, что процесс может использовать только один блок, как мы видели раньше. Просто для удобства разделим память на так называемые страницы и позволим процессам видеть память постранично. То есть процесс может видеть x страниц памяти. При этом с точки зрения процесса было бы здорово, если бы он ничего не знал про эту сложную организацию памяти, про все эти пустые и непустые участки, про нелинейный рост памяти. Было бы здорово, если бы процесс видел память так, как если бы она была идеально сделана только для него и ничего другого не существовало. Это и есть идея подкачки страниц и впоследствии виртуальной памяти.
![[Pasted image 20250120230655 1.png]]
Слева вы видите ту картину, которую видит процесс. Процесс видит память. Операционная система дала ему такой кусок памяти. Эта память состоит из страниц, и процесс думает: «Вау, здорово, целый ровный последовательный кусок памяти! Совсем не похоже на то, что у меня там пугали, рассказывали про кучу фрагментации, каких-то непоследовательных кусков. Все общее идеально». И с точки зрения процесса все на самом деле идеально. Однако за кулисами, или «под капотом», операционная система перенаправляет каждую из этих страниц на реальную страницу физической памяти.

Вот эти страницы в логической памяти, то есть в памяти, которую видит процесс, мы называем страницами («pages»), а страницы или разделы физической памяти называются фреймами («frames»). Тут важно сделать так, чтобы они были одинаковыми по размеру. Мы сейчас увидим почему, но как минимум потому, что нам нужно удобство и простота соответствия один к одному. Вот эта страница, которая для процесса выглядит второй по счету, на самом деле оказалась на втором фрейме в физической памяти. Но третья по счету страница — последняя в физической памяти.

Процессу не нужно знать эту страшную картину непоследовательности. Процессу кажется, что все отлично. И так как они одинакового размера, мы можем в точности сказать, что эта страница соответствует этому фрейму физической памяти. Я думаю, вы можете представить, как это организовать. Нам просто нужно описать, какая страница относится к какой странице физической памяти. Нам нужна некая таблица соответствия или некая функция. Эту функцию выполняет так называемый «memory management unit» («менеджмент юнит» или юнит управления памятью).
![[Pasted image 20250120230801.png]]

Этот механизм, естественно, работает с помощью центрального процессора. Он использует так называемую таблицу страниц («page table»), которая хранится в операционной системе. Операционная система следит за этим распределением. В этой таблице, грубо говоря, написано, что страница 1 для этого процесса соответствует такому-то адресу физической памяти, страница 2 для этого процесса соответствует такой-то странице физической памяти, и так далее. Этот механизм менеджмента памяти использует эту таблицу и данные. Каждый раз, когда процесс обращается к своей идеальной ровной памяти, она перенаправляется в настоящую локацию — в то место, где она на самом деле находится.

Естественно, когда процесс обращается к памяти, он обращается не к целым страницам. Ему нужны какие-то конкретные данные. Чаще всего эти данные находятся где-то внутри этой страницы, на каком-то расстоянии от начала или конца. И тут приходит ещё один плюс того, почему страницы и фреймы должны быть одинакового размера. Когда процессу нужно обратиться к какой-то области памяти на странице, то он обращается к этой области с помощью двух чисел. Первое число — это номер страницы. Например, он может сказать: «Окей, мне нужна вторая страница». Но в этой странице ему нужна конкретная область памяти, и эта область памяти начинается на каком-то расстоянии от начала страницы. Допустим, 27 байт от начала страницы. Это второе число, так называемый отступ или «offset».

![[Pasted image 20250120230832.png]]
Чтобы сконвертировать страницу в физическую страницу, нам нужен этот номер, менеджмент юнит и таблица, которая хранится в операционной системе. Мы получаем физический фрейм. Но вот этот отступ остаётся таким же, потому что мы знаем, что страницы и фреймы одинакового размера. Эти отступы работают, и они помогают обратиться к конкретной области в памяти.

И тут мы подходим к той идее, которая уже давно существует и процветает — **виртуальная память**. Грубо говоря, вы не узнаете ничего нового, это та же самая идея. Но теперь представьте, что мы можем использовать вторичный носитель, такой как жёсткий диск, для того чтобы хранить там эти страницы памяти. Мотивация здесь в том, что процесс обычно не использует всю доступную память. Они говорят: «Да, нам нужно два гигабайта», но в какой-то момент времени они не используют все эти два гигабайта. Точнее, все два гигабайта почти никогда не используются. Процесс может запросить 2 ГБ памяти, но использовать лишь половину, пока другая память простаивает. Одновременно другим процессам может не хватать ресурсов.

Они нужны, они могут понадобиться, они должны иметь возможность использовать два гигабайта, но чаще они используют меньше. Структуры данных, которые в этих процессах используются, такие как массивы или какие-нибудь матрицы, часто имеют избыточный размер. Программист создаёт их на всякий случай чуть больше, чем нужно. Те части памяти, которые были даны процессу, могут использоваться в разное время. Например, процессу нужны те же 2 гигабайта, но одновременно он их не использует: сначала полгигабайта, потом ещё полтора. Получается, что, хоть мы и дали достаточно памяти, её использование неэффективно.


### Виртуальная память и подкачка страниц

#### Основные принципы

Чтобы эффективно использовать ресурсы, операционная система внедряет механизм виртуальной памяти. Часть неиспользуемых страниц переносится на вторичный носитель, например жёсткий диск. Это освобождает оперативную память для более активных задач. Таким образом, логическое адресное пространство процесса может превышать физическую память системы.

Когда процесс обращается к странице, отсутствующей в оперативной памяти, происходит так называемый **"page fault"** (ошибка страницы). Операционная система загружает требуемую страницу с диска. Хотя это приводит к задержкам из-за медленного доступа к диску, данный механизм позволяет запускать программы, требующие больше памяти, чем доступно.
![[Pasted image 20250120231114.png]]
Если мы вернёмся к той картине, то не поменялось ничего, кроме того, что добавилось вторичное хранилище. В любой момент времени страница может быть перенесена туда и обратно. Когда мы обращаемся к странице, и оказалось, что её нет физически в памяти, значит, она находится во вторичном хранилище. Мы называем это **page fault**. Это звучит ужасно, но на самом деле в этом нет ничего страшного. Да, это будет задержка, это будет очень медленно, потому что доступ к жёсткому диску ещё медленнее, чем к оперативной памяти. Однако этот механизм даёт гибкость и возможность работы с большими объёмами данных.

### Типы подкачки страниц

#### Ленивая подкачка (Demand Paging)

Страницы загружаются только по запросу, когда процесс обращается к ним. Это экономит ресурсы, но может вызывать задержки.

#### Упреждающая подкачка

Операционная система предугадывает, какие страницы могут понадобиться, и загружает их заранее. Принцип локальности данных предполагает, что если процесс использует страницу 27, скоро потребуется страница 28.

### Копирование при записи (Copy-On-Write)

В UNIX-подобных системах процессы часто создаются с помощью функции `fork`, которая клонирует процесс. Вместо копирования всей памяти нового процесса используется механизм **"copy-on-write"**. Оригинальный и новый процессы совместно используют одну копию памяти для чтения. Только при записи в память создаётся её отдельная копия, что экономит ресурсы.
![[Pasted image 20250121141341.png]]
Copy-On-Write выглядит следующим образом: у нас есть процесс 1. Мы сделали его копию — процесс 2. Он всё ещё использует ту же физическую память. С точки зрения процесса кажется, что у него своя изолированная память. Однако если процесс решает что-то записать, тогда создаётся отдельная копия.


### Основные проблемы и ограничения

#### Трэшинг (Thrashing)

Если система слишком часто переносит данные между оперативной памятью и диском, она тратит больше времени на эти операции, чем на выполнение реальных задач.

#### SSD-диски

Они быстрее жёстких дисков, но имеют ограниченное количество циклов записи. Постоянная подкачка ускоряет износ SSD, что стоит учитывать при настройке системы.


### Заключение

Механизмы виртуальной памяти и подкачки помогают операционным системам эффективно управлять ограниченными ресурсами. Несмотря на задержки и ограничения, такие подходы позволяют запускать современные ресурсоёмкие программы. Как сказал (якобы) Билл Гейтс: «640 КБ должно быть достаточно для всех». В реальности, с каждым десятилетием потребности программ растут, и подходы к управлению памятью постоянно совершенствуются.